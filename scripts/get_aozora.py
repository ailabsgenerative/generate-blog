import re
import requests
from bs4 import BeautifulSoup

def get_txt_url_from_html_page(page_url: str) -> str:
    """ä½œå“ãƒšãƒ¼ã‚¸ã®HTMLã‹ã‚‰ .txt ãƒ•ã‚¡ã‚¤ãƒ«ã®URLã‚’æŠ½å‡º"""
    response = requests.get(page_url)
    response.encoding = 'shift_jis'
    soup = BeautifulSoup(response.text, 'html.parser')

    link = soup.find('a', string='ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«')
    if not link:
        raise ValueError("ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    href = link['href']
    return f"https://www.aozora.gr.jp{href}"

def download_aozora_txt(txt_url: str) -> str:
    """é’ç©ºæ–‡åº«ã®txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’URLã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    response = requests.get(txt_url)
    response.encoding = 'shift_jis'
    return response.text

def extract_main_text(text: str) -> str:
    """æœ¬æ–‡éƒ¨åˆ†ã®ã¿ã‚’æŠ½å‡ºã—ã€æ•´å½¢ã™ã‚‹"""
    start_match = re.search(r'ï¼»ï¼ƒã“ã“ã‹ã‚‰æœ¬æ–‡ï¼½', text)
    end_match = re.search(r'ï¼»ï¼ƒã“ã“ã§æœ¬æ–‡çµ‚ã‚ã‚Šï¼½', text)

    if not start_match or not end_match:
        raise ValueError("æœ¬æ–‡ã®ãƒãƒ¼ã‚«ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    main_text = text[start_match.end():end_match.start()]
    main_text = re.sub(r'ã€Š.*?ã€‹', '', main_text)
    main_text = re.sub(r'ï¼»ï¼ƒ.*?ï¼½', '', main_text)
    main_text = re.sub(r'ï½œ', '', main_text)
    main_text = re.sub(r'\n\n+', '\n\n', main_text)

    return main_text.strip()

# ä½œå“ãƒšãƒ¼ã‚¸ï¼ˆä¾‹ï¼šã“ã“ã‚ï¼‰
page_url = "https://www.aozora.gr.jp/cards/000020/files/2569_28291.html"

# ãƒ†ã‚­ã‚¹ãƒˆURLã‚’å–å¾—ã—ã¦æœ¬æ–‡ã‚’æ•´å½¢
txt_url = get_txt_url_from_html_page(page_url)
print(f"ğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆURL: {txt_url}")

raw_text = download_aozora_txt(txt_url)
clean_text = extract_main_text(raw_text)

# ä¸Šä½1000æ–‡å­—ã‚’è¡¨ç¤º
print(clean_text[:1000])
